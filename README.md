**CyberBullying Detection and Content Moderation System**
**Overview**
This project aims to create a system that automatically identifies and removes hate speech, cyberbullying, and offensive language from user-generated content. The goal is to foster a safer and more respectful online environment.

**Objectives**
Develop and implement a robust hate speech detection model.
Automate the deletion process for identified hate speech content.
Analyze the impact of cultural context on hate speech detection.
Balance freedom of expression with the need for online safety.
Provide recommendations to enhance the efficiency and accuracy of hate speech detection algorithms.

**Technologies Used**

Programming Language: Python 
Dashboard: HTML, Css , Js
Machine Learning: Custom-trained models for hate speech detection
Data: labeled_data2.csv for training and evaluation
Web Framework: Flask (as indicated by app.py)

**Repository Structure**

app.py: Main application file
hate_speech_detection.py: Contains the detection logic
train_hate_speech_model.py: Script to train the detection model
labeled_data2.csv: Dataset used for training and evaluation
templates/: HTML templates for the dashboard
model/: Directory containing trained model files

**Getting Started**

**STEP 1:**
Clone the repository:git clone https://github.com/AryaPatil-25/Cyber-Security-Project.git

cd Cyber-Security-Project

**STEP 2:**
Install dependencies:pip install -r requirements.txt

**STEP 3:**
Train the model:python train_hate_speech_model.py

**STEP 4:**
Run the application:python app.py



**Contribution**
Contributions are welcome! Please fork the repository and submit a pull request with your enhancements.
**License**
This project is licensed under the MIT License.
